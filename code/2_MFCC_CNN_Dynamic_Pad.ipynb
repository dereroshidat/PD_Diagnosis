{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58d895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1cc910",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 8000\n",
    "batch_size = 4\n",
    "train_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "640e0087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(data, sample_rate, window):\n",
    "    mfccs_list = []\n",
    "    for dat in data:\n",
    "        mfccs = librosa.feature.mfcc(y=dat, sr=sample_rate, n_mfcc=window)\n",
    "        mfccs = mfccs.T\n",
    "        mfccs_list.append(mfccs)\n",
    "    return mfccs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f92c6",
   "metadata": {},
   "source": [
    "# Load HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93771b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/mnt/c/Users/user/Desktop/Roshidat/Workspace/PD_prediction/data/1_data/HC_AH'\n",
    "dirc = os.listdir(path)\n",
    "\n",
    "hc_data = []\n",
    "for file in dirc:\n",
    "    file_path = os.path.join(path, file)\n",
    "    loaded_file, _ = librosa.load(file_path, sr=sf)\n",
    "    hc_data.append(loaded_file)\n",
    "\n",
    "len(hc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "002e6d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc_train_ratio =  int(len(hc_data) * train_ratio)\n",
    "hc_train_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8475a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hc = np.zeros(len(hc_data))  # Create an array of zeros with the same length as hc_data_padded\n",
    "y_hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd103336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc_train = hc_data[:hc_train_ratio]\n",
    "hc_test = hc_data[hc_train_ratio:]\n",
    "\n",
    "y_hc_train = y_hc[:hc_train_ratio]\n",
    "y_hc_test = y_hc[hc_train_ratio:]\n",
    "\n",
    "len(hc_train), len(hc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955b3e8",
   "metadata": {},
   "source": [
    "# Load PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b37f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_path = '/mnt/c/Users/user/Desktop/Roshidat/Workspace/PD_prediction/data/1_data/PD_AH'\n",
    "pd_dirc = os.listdir(pd_path)\n",
    "\n",
    "pd_data = []\n",
    "for file in pd_dirc:\n",
    "    file_path = os.path.join(pd_path, file)\n",
    "    loaded_file, _ = librosa.load(file_path, sr=sf)\n",
    "    pd_data.append(loaded_file)\n",
    "\n",
    "\n",
    "len(pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b6acb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pd = np.zeros(len(pd_data))+1  # Create an array of zeros with the same length as hc_data_padded\n",
    "y_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "016ad1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train_ratio =  int(len(pd_data) * train_ratio)\n",
    "\n",
    "pd_train = pd_data[:pd_train_ratio]\n",
    "pd_test = pd_data[pd_train_ratio:]\n",
    "\n",
    "y_pd_train = y_pd[:pd_train_ratio]\n",
    "y_pd_test = y_pd[pd_train_ratio:]\n",
    "\n",
    "len(pd_train), len(pd_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d23a1df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hc_train + pd_train\n",
    "y_train = np.concatenate((y_hc_train, y_pd_train))\n",
    "\n",
    "X_test = hc_test + pd_test\n",
    "y_test = np.concatenate((y_hc_test, y_pd_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "041d1517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 17, 17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cf663be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mfcc = get_mfcc(X_train, sf, 13)\n",
    "X_test_mfcc = get_mfcc(X_test, sf, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65a66d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 17)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_mfcc), len(X_test_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7b64e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mfcc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36ad8a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mfcc[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d9634ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe7352d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.data_size = len(data)\n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.label[idx], dtype=torch.long)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e18077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PDDataset(X_train_mfcc, y_train)\n",
    "test_ds = PDDataset(X_test_mfcc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5face20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([45, 13]), torch.Size([]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = train_ds[60]\n",
    "dd[0].shape, dd[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4001241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _padding(batch):\n",
    "    X, y = zip(*batch)\n",
    "    X_padded = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "\n",
    "    return (\n",
    "        X_padded,\n",
    "        torch.stack(y),\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6688de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=_padding,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=_padding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e4e5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample, y_sample = next(iter(train_loader))  # Check if the DataLoader works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cff5de91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 66, 13]), torch.Size([4]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape, y_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed6e956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PD_Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(PD_Classifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # Adaptive pooling to ensure fixed output size (e.g., 8x8)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((8, 8))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.adaptive_pool(x)  # Output shape: (batch, 32, 8, 8)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "# model = PD_Classifier(num_classes=2)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d16c4d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PD_Classifier(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=2048, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PD_Classifier(num_classes=2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42f223ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for PD_Classifier (single output neuron, sigmoid activation)\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40781c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:01,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 57, 13])\n",
      "torch.Size([4, 1, 91, 13])\n",
      "torch.Size([4, 1, 109, 13])\n",
      "torch.Size([4, 1, 104, 13])\n",
      "torch.Size([4, 1, 81, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 99, 13])\n",
      "torch.Size([4, 1, 62, 13])\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 61, 13])\n",
      "torch.Size([4, 1, 75, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 50, 13])\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "Epoch 1/10, Loss: 0.6091, Accuracy: 0.6562\n",
      "torch.Size([4, 1, 75, 13])\n",
      "torch.Size([4, 1, 63, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 63, 13])\n",
      "torch.Size([4, 1, 104, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 65, 13])\n",
      "torch.Size([4, 1, 99, 13])\n",
      "torch.Size([4, 1, 53, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:00<00:00,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 62, 13])\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 109, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 91, 13])\n",
      "torch.Size([4, 1, 43, 13])\n",
      "Epoch 2/10, Loss: 0.5389, Accuracy: 0.7344\n",
      "torch.Size([4, 1, 109, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 45, 13])\n",
      "torch.Size([4, 1, 81, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 104, 13])\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 99, 13])\n",
      "torch.Size([4, 1, 91, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 63, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 52, 13])\n",
      "torch.Size([4, 1, 58, 13])\n",
      "torch.Size([4, 1, 61, 13])\n",
      "torch.Size([4, 1, 75, 13])\n",
      "Epoch 3/10, Loss: 0.4900, Accuracy: 0.7656\n",
      "torch.Size([4, 1, 52, 13])\n",
      "torch.Size([4, 1, 57, 13])\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 75, 13])\n",
      "torch.Size([4, 1, 99, 13])\n",
      "torch.Size([4, 1, 35, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 104, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 109, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 81, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 53, 13])\n",
      "torch.Size([4, 1, 63, 13])\n",
      "torch.Size([4, 1, 52, 13])\n",
      "Epoch 4/10, Loss: 0.5101, Accuracy: 0.7656\n",
      "torch.Size([4, 1, 65, 13])\n",
      "torch.Size([4, 1, 109, 13])\n",
      "torch.Size([4, 1, 99, 13])\n",
      "torch.Size([4, 1, 81, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 49, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 75, 13])\n",
      "torch.Size([4, 1, 57, 13])\n",
      "torch.Size([4, 1, 61, 13])\n",
      "torch.Size([4, 1, 104, 13])\n",
      "torch.Size([4, 1, 59, 13])\n",
      "Epoch 5/10, Loss: 0.4300, Accuracy: 0.8125\n",
      "torch.Size([4, 1, 99, 13])\n",
      "torch.Size([4, 1, 81, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 63, 13])\n",
      "torch.Size([4, 1, 104, 13])\n",
      "torch.Size([4, 1, 75, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 62, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 49, 13])\n",
      "torch.Size([4, 1, 91, 13])\n",
      "torch.Size([4, 1, 65, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:00<00:00,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 48, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 109, 13])\n",
      "Epoch 6/10, Loss: 0.3506, Accuracy: 0.8750\n",
      "torch.Size([4, 1, 99, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 109, 13])\n",
      "torch.Size([4, 1, 53, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 56, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 75, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 63, 13])\n",
      "torch.Size([4, 1, 63, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 61, 13])\n",
      "torch.Size([4, 1, 62, 13])\n",
      "torch.Size([4, 1, 104, 13])\n",
      "torch.Size([4, 1, 81, 13])\n",
      "Epoch 7/10, Loss: 0.4608, Accuracy: 0.7812\n",
      "torch.Size([4, 1, 104, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 86, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:00<00:00,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 61, 13])\n",
      "torch.Size([4, 1, 42, 13])\n",
      "torch.Size([4, 1, 109, 13])\n",
      "torch.Size([4, 1, 58, 13])\n",
      "torch.Size([4, 1, 57, 13])\n",
      "torch.Size([4, 1, 91, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 62, 13])\n",
      "torch.Size([4, 1, 81, 13])\n",
      "torch.Size([4, 1, 99, 13])\n",
      "Epoch 8/10, Loss: 0.3598, Accuracy: 0.8125\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 109, 13])\n",
      "torch.Size([4, 1, 63, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 63, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 62, 13])\n",
      "torch.Size([4, 1, 104, 13])\n",
      "torch.Size([4, 1, 59, 13])\n",
      "torch.Size([4, 1, 75, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 99, 13])\n",
      "torch.Size([4, 1, 91, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "Epoch 9/10, Loss: 0.3328, Accuracy: 0.8594\n",
      "torch.Size([4, 1, 109, 13])\n",
      "torch.Size([4, 1, 59, 13])\n",
      "torch.Size([4, 1, 53, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 99, 13])\n",
      "torch.Size([4, 1, 61, 13])\n",
      "torch.Size([4, 1, 81, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "torch.Size([4, 1, 104, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 53, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 66, 13])\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 68, 13])\n",
      "torch.Size([4, 1, 62, 13])\n",
      "torch.Size([4, 1, 86, 13])\n",
      "Epoch 10/10, Loss: 0.3633, Accuracy: 0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        inputs = inputs.unsqueeze(1)  # Add channel dimension for CNN (batch, channels, height, width)\n",
    "        labels = labels.float().unsqueeze(1)  # Ensure shape (batch, 1) and float type\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        # acc = (y_pred.round() == y_batch).float().mean()\n",
    "        #preds = (outputs > 0.5).float()\n",
    "        preds = outputs.round()\n",
    "        correct += (preds == labels).sum().item()\n",
    "        \n",
    "        total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c205f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.3237, Test Accuracy: 58.8235\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        inputs = inputs.unsqueeze(1)  # Add channel dimension for CNN (batch, channels, height, width)\n",
    "        labels = labels.float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        #preds = (outputs > 0.5).float()\n",
    "        preds = outputs.round()\n",
    "        test_correct += (preds == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "test_loss = test_loss / test_total\n",
    "test_acc = test_correct / test_total\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc*100:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
